{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "311a0411",
   "metadata": {},
   "source": [
    "# 01_data_prep_ca_2024.ipynb\n",
    "\n",
    "## Part A — What we are doing\n",
    "\n",
    "We construct the **California analysis panel (2024)**, the master dataset used by all subsequent notebooks. This includes:\n",
    "- Filtering to California households.\n",
    "- Excluding **negative AGI** households.\n",
    "- Deriving analysis status (**Single vs Married Households**) from **spouse presence in the household**.\n",
    "- Creating size buckets (cap at 7).\n",
    "- **Calibrating weights** to official 2023 household distribution by status × size.\n",
    "- **Scaling weights** to the 2024 benchmark (14.8 million households).\n",
    "- Computing the **consumption allowance** schedule.\n",
    "- Applying the **AGI-based phase-out**.\n",
    "- Writing the panel to `intermediate/ca_panel_2024.parquet` (or `.csv`).\n",
    "\n",
    "**Outputs (core)**\n",
    "- `intermediate/ca_panel_2024.parquet` or `intermediate/ca_panel_2024.csv`\n",
    "- `intermediate/weight_scaling_2024.json` (metadata on calibration & scaling)\n",
    "- A weighted **household size × status** diagnostic table.\n",
    "\n",
    "**Why this matters**  \n",
    "All totals, distributional analysis, and MTR calculations rely on this standardized, reproducible panel. Anchoring weights to ACS-based benchmarks ensures statewide totals and household composition are accurate.\n",
    "\n",
    "---\n",
    "\n",
    "## Part B — Inputs & prior steps\n",
    "\n",
    "- **Reads:** `config/columns.yaml` produced by `00_repo_audit_and_config_2024.ipynb`.\n",
    "- **Draws:** PolicyEngine household arrays for 2024, mapped to the resolved names.\n",
    "- **Benchmarks:** 2023 ACS/DOF household counts by status × size bucket.\n",
    "\n",
    "---\n",
    "\n",
    "## Part C — Identify California households\n",
    "\n",
    "We build a **robust CA filter** that recognizes:\n",
    "- String codes: `\"CA\"`, `\"California\"`\n",
    "- Numeric FIPS: `6`, `06`\n",
    "\n",
    "We keep only households where `state_code` matches CA according to the rules above.\n",
    "\n",
    "**Result:** A boolean mask `MASK_CA` used to slice all arrays and fields.\n",
    "\n",
    "---\n",
    "\n",
    "## Part D — Select weights\n",
    "\n",
    "We map the chosen **household weight** to `household_weight` in the panel. We verify:\n",
    "- Total weight overall and within CA are **positive**.\n",
    "- The weight is at the household level (not person-level).\n",
    "\n",
    "**Why this matters**  \n",
    "All totals and shares depend on this weight. Using the wrong weight distorts the entire analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Part E — Derive analysis “filing status” (Single vs Married Households)\n",
    "\n",
    "We do **not** trust tax-unit filing status for household grouping because spouses can file jointly while not co-residing. Instead:\n",
    "\n",
    "- **Married Households** (= MFJ proxy):  \n",
    "  spouse present (e.g., `spouse_present == True` or `head_spouse_count ≥ 2`) **AND** not Head-of-Household **AND** `household_size ≥ 2`.\n",
    "- **Single Households**: everyone else (including HOH and MFS).\n",
    "\n",
    "**Invariant**  \n",
    "There should be **no Married Households with size 1**.  \n",
    "If such rows appear, we reclassify them to Single but preserve their weights.  \n",
    "\n",
    "**Singles can have size ≥ 2** (single parent + kids, multigenerational without a spouse).\n",
    "\n",
    "We store:\n",
    "- `is_married_couple` ∈ {0,1}\n",
    "- `filing_status` ∈ {`\"single\"`, `\"mfj\"`}\n",
    "\n",
    "---\n",
    "\n",
    "## Part F — Calibrate weights to ACS/DOF 2023 benchmarks\n",
    "\n",
    "- Household weights from CPS scaling run “hot” (~16M households).  \n",
    "- We recalibrate to match **ACS/DOF 2023 household distribution** by status × size bucket:  \n",
    "\n",
    "  - Singles: 1-person = 3.379M, 2-person = 1.255M, … 7+ = 0.069M  \n",
    "  - Married: 2-person = 2.472M, 3-person = 1.359M, … 7+ = 0.241M  \n",
    "\n",
    "- Calibration step computes bucket-specific scale factors = target ÷ CPS.  \n",
    "- Each household’s weight is multiplied by the factor for its status × size bucket.  \n",
    "- This preserves within-bucket variation but fixes statewide composition.\n",
    "\n",
    "---\n",
    "\n",
    "## Part G — Scale weights to 2024 total\n",
    "\n",
    "- After bucket calibration, the 2023 total is ≈13.6M households.  \n",
    "- We apply a **uniform scale factor** so the final weighted total equals **14.8M households** (Kyle’s 2024 benchmark).  \n",
    "- Metadata on both calibration and scaling is saved to `intermediate/weight_scaling_2024.json`.\n",
    "\n",
    "---\n",
    "\n",
    "## Part H — Compute consumption allowance & phase-out\n",
    "\n",
    "- `size_bucket = min(household_size, 7)` (integer 1..7).\n",
    "- Consumption-allowance schedules (poverty-guideline based) applied by status and size.\n",
    "- **Guard:** married allowance is never applied to size 1.\n",
    "- Phase-out thresholds and ranges (after update):\n",
    "  - `THRESHOLDS  = {\"single\": 50_000, \"mfj\": 100_000}`\n",
    "  - `PHASE_RANGE = {\"single\": 50_000, \"mfj\": 100_000}`  \n",
    "  → Singles phase out 50k–100k, MFJ phase out 100k–200k.\n",
    "\n",
    "We store:\n",
    "- `consumption_allowance`\n",
    "- `rebate_after_phaseout`\n",
    "- `allowance_no_phaseout`, `allowance_phaseout` (compatibility aliases)\n",
    "- `excess_over_threshold`\n",
    "\n",
    "---\n",
    "\n",
    "## Part I — Diagnostics, deliverables & acceptance checks\n",
    "\n",
    "**Diagnostics (printed)**\n",
    "- Weighted household **size × status** table (thousands).\n",
    "- Counts of **excluded negative-AGI** households.\n",
    "- Pre- vs post-calibration totals, scale factors.\n",
    "\n",
    "**Files written**\n",
    "- `intermediate/ca_panel_2024.parquet` or `intermediate/ca_panel_2024.csv`\n",
    "- `intermediate/weight_scaling_2024.json`\n",
    "\n",
    "**Acceptance checks**\n",
    "- Panel exists in `intermediate/`.\n",
    "- No “Married Households, size 1”.\n",
    "- Household totals ≈14.8M after scaling.\n",
    "- `consumption_allowance ≥ rebate_after_phaseout` row-wise.\n",
    "- All required columns present:\n",
    "  - `household_size`, `household_weight`, `household_agi`, `employment_income`\n",
    "  - `filing_status`, `is_married_couple`, `size_bucket`\n",
    "  - `consumption_allowance`, `rebate_after_phaseout`, `excess_over_threshold`\n",
    "\n",
    "---\n",
    "\n",
    "## Part J — Troubleshooting\n",
    "\n",
    "- **Totals not ≈14.8M**: Check that bucket calibration factors were applied before final scaling.  \n",
    "- **Married size 1 appears**: Ensure reclassification guard runs before calibration.  \n",
    "- **Parquet engine missing**: Notebook falls back to `.csv`. Downstream supports both.  \n",
    "- **Downstream totals don’t match Step 02**: Make sure you’re using the scaled `household_weight`, not `household_weight_raw`.\n",
    "\n",
    "---\n",
    "\n",
    "## Part K — How to rerun\n",
    "\n",
    "1. Re-run `00` to refresh column mappings if inputs changed.  \n",
    "2. Re-run this notebook to rebuild the calibrated 2024 CA panel.  \n",
    "3. Verify diagnostics (size × status table, totals ≈14.8M).  \n",
    "4. Proceed to Step 02 for rebate costs.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73130906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 01 start.\n",
      "Loaded: c:\\Users\\Ali.Melad\\Dropbox\\Ali Work\\Kyle\\California VAT\\policy_engile_cali_v2\\policy\\vat_rebate.py\n",
      "col_map: {'agi': 'adjusted_gross_income', 'wages': 'employment_income', 'hh_size': 'household_size', 'weight': 'household_weight', 'fed_tax': 'income_tax', 'state_tax': 'ca_income_tax', 'filing_status': 'filing_status'}\n",
      "CA households (raw rows): 1777\n",
      "[info] spouse signal used: head_spouse_count>=2\n",
      "filing_status counts: {'mfj': 1131, 'single': 646}\n",
      "Excluded negative-AGI households: 30\n",
      "[fix] Applied 11% deflator to weights: total 16,215,270 → 14,431,592\n",
      "parquet save failed; writing CSV: A type extension with name pandas.period already defined\n",
      "saved ../intermediate/ca_panel_2024.csv rows: 1747\n",
      "wrote ../intermediate/weight_scaling_2024.json\n",
      "\n",
      "Weighted CA households (thousands) by size × status (final, after deflator):\n",
      "                 Married       Single\n",
      "size_bucket                          \n",
      "1               0.000000  4224.299805\n",
      "2            3397.500000  1033.199951\n",
      "3            3233.500000    49.200001\n",
      "4             528.900024   736.700012\n",
      "5             805.500000    15.700000\n",
      "6              48.400002   201.899994\n",
      "7             132.899994    24.000000\n",
      "\n",
      "✅ Step 01 complete.\n"
     ]
    }
   ],
   "source": [
    "# 01 — Data prep CA (2024; household-level; MFJ via spouse/HOH; exclude AGI<0; apply 11% weight deflator)\n",
    "import os, yaml, numpy as np, pandas as pd, importlib.util, json\n",
    "from policyengine_us import Microsimulation\n",
    "\n",
    "print(\"Step 01 start.\")\n",
    "\n",
    "# Load vat_rebate helpers\n",
    "vat_path = os.path.abspath(\"../policy/vat_rebate.py\")\n",
    "spec = importlib.util.spec_from_file_location(\"vat_rebate\", vat_path)\n",
    "vr = importlib.util.module_from_spec(spec); spec.loader.exec_module(vr)\n",
    "print(\"Loaded:\", vr.__file__)\n",
    "\n",
    "# Load column mapping\n",
    "with open(\"../config/columns.yaml\") as f:\n",
    "    col_map = yaml.safe_load(f)\n",
    "print(\"col_map:\", col_map)\n",
    "\n",
    "os.makedirs(\"../intermediate\", exist_ok=True)\n",
    "sim = Microsimulation()\n",
    "YEAR = 2024\n",
    "\n",
    "def hcalc(var, decode_enums=True):\n",
    "    return pd.Series(sim.calculate(var, map_to=\"household\", period=YEAR, decode_enums=decode_enums))\n",
    "\n",
    "# 1) Pull household-level arrays \n",
    "state_code       = hcalc(\"state_code\", decode_enums=True).astype(str).str.strip().str.upper()\n",
    "household_size   = hcalc(col_map[\"hh_size\"], decode_enums=False)\n",
    "household_weight = hcalc(col_map[\"weight\"],  decode_enums=False)\n",
    "agi              = hcalc(col_map[\"agi\"],     decode_enums=False)\n",
    "wages            = hcalc(col_map[\"wages\"],   decode_enums=False)\n",
    "fed_tax          = hcalc(col_map[\"fed_tax\"], decode_enums=False)\n",
    "state_tax        = hcalc(col_map[\"state_tax\"], decode_enums=False)\n",
    "\n",
    "# Household-level spouse/HOH signals\n",
    "def try_household(var, decode=False):\n",
    "    try:\n",
    "        return pd.Series(sim.calculate(var, map_to=\"household\", period=YEAR, decode_enums=decode))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "has_spouse   = try_household(\"has_spouse\", decode=False)\n",
    "spouse_pres  = try_household(\"spouse_present\", decode=False)\n",
    "spouse_count = try_household(\"head_spouse_count\", decode=False)\n",
    "hoh_elig     = try_household(\"head_of_household_eligible\", decode=False)\n",
    "\n",
    "# 2) Build CA DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"state_code\": state_code,\n",
    "    \"household_size\": pd.to_numeric(household_size, errors=\"coerce\"),\n",
    "    \"household_weight\": pd.to_numeric(household_weight, errors=\"coerce\"),\n",
    "    \"household_agi\": pd.to_numeric(agi, errors=\"coerce\"),\n",
    "    \"employment_income\": pd.to_numeric(wages, errors=\"coerce\"),\n",
    "    \"fed_income_tax\": pd.to_numeric(fed_tax, errors=\"coerce\"),\n",
    "    \"ca_income_tax\": pd.to_numeric(state_tax, errors=\"coerce\"),\n",
    "})\n",
    "mask_ca = df[\"state_code\"].eq(\"CA\")\n",
    "df = df.loc[mask_ca].reset_index(drop=True)\n",
    "print(\"CA households (raw rows):\", len(df))\n",
    "\n",
    "# 3) Align spouse/HOH to df\n",
    "def align_to_df(s):\n",
    "    if s is None: \n",
    "        return None\n",
    "    s = pd.to_numeric(pd.Series(s), errors=\"coerce\")\n",
    "    return s.loc[mask_ca].reset_index(drop=True)\n",
    "\n",
    "has_spouse   = align_to_df(has_spouse)\n",
    "spouse_pres  = align_to_df(spouse_pres)\n",
    "spouse_count = align_to_df(spouse_count)\n",
    "hoh_elig     = align_to_df(hoh_elig)\n",
    "\n",
    "# 4) Derive filing_status: HOH ⇒ single; else spouse ⇒ mfj; else single.\n",
    "if has_spouse is not None:\n",
    "    spouse_any = has_spouse.fillna(0).astype(bool)\n",
    "    source_used = \"has_spouse\"\n",
    "elif spouse_pres is not None:\n",
    "    spouse_any = spouse_pres.fillna(0).astype(bool)\n",
    "    source_used = \"spouse_present\"\n",
    "elif spouse_count is not None:\n",
    "    uniq = np.sort(spouse_count.dropna().unique())\n",
    "    if len(uniq) and uniq.max() >= 2:\n",
    "        spouse_any = (spouse_count.fillna(0) >= 2)\n",
    "        source_used = \"head_spouse_count>=2\"\n",
    "    else:\n",
    "        spouse_any = (spouse_count.fillna(0) > 0)\n",
    "        source_used = \"head_spouse_count>0\"\n",
    "else:\n",
    "    spouse_any = pd.Series(False, index=df.index)\n",
    "    source_used = \"no_spouse_signal\"\n",
    "\n",
    "hoh_any = (hoh_elig.fillna(0) > 0) if hoh_elig is not None else pd.Series(False, index=df.index)\n",
    "\n",
    "filing_status = np.where(hoh_any, \"single\", np.where(spouse_any, \"mfj\", \"single\"))\n",
    "df[\"filing_status\"] = filing_status.astype(str)\n",
    "df[\"is_married_couple\"] = (df[\"filing_status\"].str.lower() == \"mfj\").astype(int)\n",
    "\n",
    "print(f\"[info] spouse signal used: {source_used}\")\n",
    "print(\"filing_status counts:\", df[\"filing_status\"].value_counts().to_dict())\n",
    "\n",
    "# Guard: reclassify impossible \"married & size<2\" to single\n",
    "df[\"household_size\"] = df[\"household_size\"].fillna(1).round().astype(int)\n",
    "bad_m1 = (df[\"is_married_couple\"] == 1) & (df[\"household_size\"] < 2)\n",
    "if bad_m1.any():\n",
    "    n_bad = int(bad_m1.sum())\n",
    "    w_bad = float(df.loc[bad_m1, \"household_weight\"].sum())\n",
    "    print(f\"[fix] Reclassifying {n_bad:,} rows (weighted {w_bad:,.0f}) from married->single because size<2.\")\n",
    "    df.loc[bad_m1, \"is_married_couple\"] = 0\n",
    "    df.loc[bad_m1, \"filing_status\"] = \"single\"\n",
    "\n",
    "# 5) Exclude negative AGI, set size bucket\n",
    "before = len(df)\n",
    "df = df.loc[df[\"household_agi\"] >= 0].reset_index(drop=True)\n",
    "print(\"Excluded negative-AGI households:\", before - len(df))\n",
    "df[\"size_bucket\"] = np.clip(df[\"household_size\"], 1, 7).astype(int)\n",
    "\n",
    "# 6) Apply simple 11% deflator (reduce weights by 11%)\n",
    "wt_pre = float(df[\"household_weight\"].sum())\n",
    "df[\"household_weight\"] = df[\"household_weight\"] * 0.89\n",
    "wt_post = float(df[\"household_weight\"].sum())\n",
    "print(f\"[fix] Applied 11% deflator to weights: total {wt_pre:,.0f} → {wt_post:,.0f}\")\n",
    "\n",
    "# 7) Compute allowance + phaseout\n",
    "df = vr.compute_allowance(df)\n",
    "df = vr.apply_phaseout(df)\n",
    "\n",
    "df[\"allowance_no_phaseout\"] = df[\"consumption_allowance\"]\n",
    "df[\"allowance_phaseout\"]    = df[\"rebate_after_phaseout\"]\n",
    "\n",
    "# 8) Save intermediate\n",
    "os.makedirs(\"../intermediate\", exist_ok=True)\n",
    "parq = \"../intermediate/ca_panel_2024.parquet\"\n",
    "csv  = \"../intermediate/ca_panel_2024.csv\"\n",
    "try:\n",
    "    df.to_parquet(parq, index=False)\n",
    "    print(\"saved\", parq, \"rows:\", len(df))\n",
    "except Exception as e:\n",
    "    print(\"parquet save failed; writing CSV:\", e)\n",
    "    df.to_csv(csv, index=False)\n",
    "    print(\"saved\", csv, \"rows:\", len(df))\n",
    "\n",
    "# Metadata file\n",
    "meta = {\n",
    "    \"year\": 2024,\n",
    "    \"pre_deflator_total\": wt_pre,\n",
    "    \"post_deflator_total\": wt_post,\n",
    "    \"deflator_applied\": 0.89,\n",
    "    \"notes\": \"Applied uniform 11% downward adjustment to household weights.\"\n",
    "}\n",
    "with open(\"../intermediate/weight_scaling_2024.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(\"wrote ../intermediate/weight_scaling_2024.json\")\n",
    "\n",
    "# 9) Sanity print\n",
    "w = df[\"household_weight\"].fillna(0.0)\n",
    "tab = (w.groupby([df[\"size_bucket\"], np.where(df[\"is_married_couple\"]==1,\"Married\",\"Single\")])\n",
    "         .sum().unstack(1).fillna(0.0)/1_000).round(1)\n",
    "tab.index.name = \"size_bucket\"\n",
    "print(\"\\nWeighted CA households (thousands) by size × status (final, after deflator):\")\n",
    "print(tab.to_string())\n",
    "\n",
    "print(\"\\n✅ Step 01 complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policyengine_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
