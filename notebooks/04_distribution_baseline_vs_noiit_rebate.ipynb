{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c762f4",
   "metadata": {},
   "source": [
    "# 04_distribution_baseline_vs_noiit_rebate_2024.ipynb\n",
    "\n",
    "## Part A — What we are doing\n",
    "\n",
    "We produce a **distributional analysis** comparing:\n",
    "- **Baseline burden** = federal income tax + CA income tax.\n",
    "- **Reform burden** = baseline burden − rebate (income taxes removed in the reform scenario; rebate added as a negative burden).\n",
    "\n",
    "We group by **equivalized income deciles** (AGI ÷ size) and extend with **Top 5%** and **Top 1%** groups using **weighted percentiles**.\n",
    "\n",
    "**Output**\n",
    "- `outputs/vat/distribution_2024.csv` — for each group: mean baseline, mean reform, mean change, share of total change, population share.\n",
    "\n",
    "---\n",
    "\n",
    "## Part B — Inputs & dependencies\n",
    "\n",
    "- **Reads:** `intermediate/ca_panel_2024.(parquet|csv)` from `01`.\n",
    "- Fields needed:\n",
    "  - `fed_income_tax`, `ca_income_tax`, `rebate_after_phaseout`\n",
    "  - `household_weight`, `household_agi`, `household_size`\n",
    "\n",
    "---\n",
    "\n",
    "## Part C — Group construction\n",
    "\n",
    "1. **Equivalized income**: `equiv_income = household_agi / household_size`.\n",
    "2. **Deciles**: weighted deciles D1–D10 using `household_weight`.\n",
    "3. **Top 5% / Top 1%**: find weighted percentile cutoffs **within the full distribution** and tag households accordingly. These groups can overlap with D10; typically we present them as **additional rows**.\n",
    "\n",
    "---\n",
    "\n",
    "## Part D — Measures & checks\n",
    "\n",
    "For each group:\n",
    "- `baseline_burden = fed_income_tax + ca_income_tax`\n",
    "- `reform_burden = baseline_burden − rebate_after_phaseout`\n",
    "- `change = reform_burden − baseline_burden = −rebate_after_phaseout`\n",
    "- Compute **means** using `household_weight`.\n",
    "- Compute **group population share** (weight share).\n",
    "- Compute **share of total change** = group’s total change / statewide total change.\n",
    "\n",
    "**Consistency checks**\n",
    "- Population shares (deciles) sum to ~**100%** (within rounding).\n",
    "- Sum of **group total changes** equals statewide total change (matches totals from `02`).\n",
    "\n",
    "---\n",
    "\n",
    "## Part E — Deliverables & acceptance checks\n",
    "\n",
    "**File written**\n",
    "- `outputs/vat/distribution_2024.csv`\n",
    "\n",
    "**Acceptance checks**\n",
    "- No missing values in burdens or weights.\n",
    "- Population shares ≈ 100% across deciles.\n",
    "- Aggregated totals align with `02_rebate_costs_2024.csv` (with-phase totals).\n",
    "\n",
    "---\n",
    "\n",
    "## Part F — Troubleshooting\n",
    "\n",
    "- **Shares don’t sum to ~100%**: verify weighted decile construction matches that in `02` and includes all households (no dropped rows).\n",
    "- **Top 1%/5%** weird: confirm weighted percentile calculation and that the groups are additional (not replacing decile rows).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f5e76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel shape: (1747, 15)\n",
      "[diag] Weighted CA households (after Step 01 deflator): 14,431,591\n",
      "✅ wrote ../outputs/vat/distribution_2024.csv\n",
      " year     group  mean_tax_baseline  mean_tax_reform    mean_change  total_change  pop_share  share_of_total_change\n",
      " 2024  decile_1       -2872.822215    -25898.613460  -23025.791244 -3.873445e+10  11.656511               5.310214\n",
      " 2024  decile_2       -3991.946629    -33841.191272  -29849.244643 -4.167621e+10   9.674770               5.713509\n",
      " 2024  decile_3       -2409.696341    -25423.767794  -23014.071454 -3.051337e+10   9.187187               4.183164\n",
      " 2024  decile_4        1268.987251    -31509.576082  -32778.563333 -4.700118e+10   9.935841               6.443524\n",
      " 2024  decile_5        3402.169128    -23703.028007  -27105.197135 -3.743732e+10   9.570574               5.132388\n",
      " 2024  decile_6        7719.960272    -20086.725324  -27806.685595 -4.283080e+10  10.673153               5.871795\n",
      " 2024  decile_7        7858.732347    -26360.531810  -34219.264157 -4.629436e+10   9.374394               6.346624\n",
      " 2024  decile_8       22872.541177     -8840.698294  -31713.239471 -5.302413e+10  11.585607               7.269228\n",
      " 2024  decile_9       72222.304037         0.000000  -72222.304037 -8.972375e+10   8.608389              12.300482\n",
      " 2024 decile_10      215131.474837         0.000000 -215131.474837 -3.021972e+11   9.733574              41.429071\n",
      " 2024  top_5pct      339869.858969         0.000000 -339869.858969 -2.521785e+11   5.141398              34.571864\n",
      " 2024  top_1pct      493836.596313         0.000000 -493836.596313 -1.011859e+11   1.419785              13.871859\n"
     ]
    }
   ],
   "source": [
    "# 04 — Distribution (2024): Baseline vs No income tax + VAT rebate (phase-out)\n",
    "import os, numpy as np, pandas as pd, importlib.util\n",
    "\n",
    "# Load helpers\n",
    "vat_path = os.path.abspath(\"../policy/vat_rebate.py\")\n",
    "spec = importlib.util.spec_from_file_location(\"vat_rebate\", vat_path)\n",
    "vr = importlib.util.module_from_spec(spec); spec.loader.exec_module(vr)\n",
    "\n",
    "os.makedirs(\"../outputs/vat\", exist_ok=True)\n",
    "\n",
    "# Load Step 01 panel\n",
    "parq = \"../intermediate/ca_panel_2024.parquet\"\n",
    "csv  = \"../intermediate/ca_panel_2024.csv\"\n",
    "panel_path = parq if os.path.exists(parq) else (csv if os.path.exists(csv) else None)\n",
    "if panel_path is None:\n",
    "    raise FileNotFoundError(\"Missing panel; run Step 01.\")\n",
    "df = pd.read_parquet(panel_path) if panel_path.endswith(\".parquet\") else pd.read_csv(panel_path)\n",
    "print(\"Panel shape:\", df.shape)\n",
    "\n",
    "# Normalize weight\n",
    "if \"weight\" not in df.columns:\n",
    "    wcol = [c for c in df.columns if c.lower() in (\"household_weight\",\"weight\",\"hh_weight\")]\n",
    "    if not wcol:\n",
    "        raise KeyError(\"No weight column found.\")\n",
    "    df[\"weight\"] = pd.to_numeric(df[wcol[0]], errors=\"coerce\").fillna(0.0)\n",
    "else:\n",
    "    df[\"weight\"] = pd.to_numeric(df[\"weight\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "print(f\"[diag] Weighted CA households (after Step 01 deflator): {df['weight'].sum():,.0f}\")\n",
    "\n",
    "# Ensure required columns; (re)compute allowance/phaseout if missing\n",
    "need_cols = {\n",
    "    \"household_agi\",\"household_size\",\"fed_income_tax\",\"ca_income_tax\",\n",
    "    \"consumption_allowance\",\"rebate_after_phaseout\"\n",
    "}\n",
    "missing = [c for c in need_cols if c not in df.columns]\n",
    "if missing:\n",
    "    recompute = set([\"consumption_allowance\",\"rebate_after_phaseout\"]).intersection(missing)\n",
    "    if recompute:\n",
    "        if {\"size_bucket\",\"is_married_couple\"}.issubset(df.columns):\n",
    "            if \"consumption_allowance\" not in df: df = vr.compute_allowance(df)\n",
    "            if \"rebate_after_phaseout\" not in df: df = vr.apply_phaseout(df)\n",
    "        else:\n",
    "            raise KeyError(f\"Need size_bucket + is_married_couple to compute allowance/phaseout; missing: {missing}\")\n",
    "    # check again\n",
    "    missing2 = [c for c in need_cols if c not in df.columns]\n",
    "    if missing2:\n",
    "        raise KeyError(f\"Still missing required columns: {missing2}\")\n",
    "\n",
    "# Baseline vs reform burdens (household-level)\n",
    "baseline_tax = (\n",
    "    df[\"fed_income_tax\"].astype(float).fillna(0.0)\n",
    "  + df[\"ca_income_tax\"].astype(float).fillna(0.0)\n",
    ")\n",
    "# Reform removes income taxes and adds the rebate as a negative burden\n",
    "reform_tax = - df[\"rebate_after_phaseout\"].astype(float).fillna(0.0)\n",
    "\n",
    "# Equivalized income and weighted deciles (AGI / size)\n",
    "df[\"equiv_income\"] = (\n",
    "    df[\"household_agi\"].astype(float) / np.maximum(df[\"household_size\"].astype(float), 1.0)\n",
    ")\n",
    "df = vr.add_weighted_deciles(df, income_col=\"equiv_income\", weight_col=\"weight\", label=\"decile\")\n",
    "\n",
    "# Weighted percentiles for Top 5% and Top 1%\n",
    "s = df[[\"equiv_income\",\"weight\"]].sort_values(\"equiv_income\").reset_index(drop=True)\n",
    "cw = s[\"weight\"].cumsum()\n",
    "tot = s[\"weight\"].sum()\n",
    "p95 = s.loc[cw >= 0.95*tot, \"equiv_income\"].iloc[0]\n",
    "p99 = s.loc[cw >= 0.99*tot, \"equiv_income\"].iloc[0]\n",
    "df[\"top_5pct\"] = (df[\"equiv_income\"] >= p95).astype(int)\n",
    "df[\"top_1pct\"] = (df[\"equiv_income\"] >= p99).astype(int)\n",
    "\n",
    "def wmean(x, w):\n",
    "    x = x.astype(float); w = w.astype(float); T = w.sum()\n",
    "    return float((x*w).sum()/T) if T>0 else np.nan\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Deciles 1..10 (sorted numerically)\n",
    "deciles_sorted = sorted(map(int, df[\"decile\"].dropna().astype(int).unique()))\n",
    "for d in deciles_sorted:\n",
    "    g = df[df[\"decile\"].astype(int) == d]\n",
    "    w = g[\"weight\"]\n",
    "    mb = wmean(baseline_tax.loc[g.index], w)\n",
    "    mr = wmean(reform_tax.loc[g.index], w)\n",
    "    dlt = (reform_tax.loc[g.index] - baseline_tax.loc[g.index]) * w\n",
    "    rows.append({\n",
    "        \"year\": 2024,\n",
    "        \"group\": f\"decile_{d}\",\n",
    "        \"mean_tax_baseline\": mb,\n",
    "        \"mean_tax_reform\":   mr,\n",
    "        \"mean_change\":       mr - mb,\n",
    "        \"total_change\":      float(dlt.sum()),\n",
    "        \"pop_share\":         float(100.0 * w.sum()/df[\"weight\"].sum()),\n",
    "    })\n",
    "\n",
    "# Top 5% and Top 1%\n",
    "for label, mask in [(\"top_5pct\", df[\"top_5pct\"].eq(1)), (\"top_1pct\", df[\"top_1pct\"].eq(1))]:\n",
    "    g = df[mask]\n",
    "    w = g[\"weight\"]\n",
    "    mb = wmean(baseline_tax.loc[g.index], w)\n",
    "    mr = wmean(reform_tax.loc[g.index], w)\n",
    "    dlt = (reform_tax.loc[g.index] - baseline_tax.loc[g.index]) * w\n",
    "    rows.append({\n",
    "        \"year\": 2024,\n",
    "        \"group\": label,\n",
    "        \"mean_tax_baseline\": mb,\n",
    "        \"mean_tax_reform\":   mr,\n",
    "        \"mean_change\":       mr - mb,\n",
    "        \"total_change\":      float(dlt.sum()),\n",
    "        \"pop_share\":         float(100.0 * w.sum()/df[\"weight\"].sum()),\n",
    "    })\n",
    "\n",
    "dist = pd.DataFrame(rows)\n",
    "\n",
    "# Share of total change (deciles only; should sum ~100 across deciles)\n",
    "dec_mask = dist[\"group\"].str.startswith(\"decile_\")\n",
    "total_delta_deciles = dist.loc[dec_mask, \"total_change\"].sum()\n",
    "dist[\"share_of_total_change\"] = 100.0 * dist[\"total_change\"] / total_delta_deciles\n",
    "\n",
    "# Integrity checks: decile pop shares ~100; statewide change consistency\n",
    "assert np.isclose(dist.loc[dec_mask, \"pop_share\"].sum(), 100.0, atol=0.2), \"Decile pop shares should sum to ~100%\"\n",
    "\n",
    "statewide_change = float(((reform_tax - baseline_tax) * df[\"weight\"]).sum())\n",
    "decile_sum_change = float(dist.loc[dec_mask, \"total_change\"].sum())\n",
    "assert np.isclose(decile_sum_change, statewide_change, rtol=1e-8, atol=1.0), \\\n",
    "    \"Decile total_change does not match statewide change.\"\n",
    "\n",
    "# Save\n",
    "out = \"../outputs/vat/distribution_2024.csv\"\n",
    "dist.to_csv(out, index=False)\n",
    "print(\"✅ wrote\", out)\n",
    "print(dist.head(12).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policyengine_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
